knitr::opts_chunk$set(message = FALSE,
warning = FALSE)
options(scipen=999)
# dependencies ----
library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr)
library(ggplot2)
library(effsize)
library(janitor)
library(tibble)
#library(sn)
library(metafor)
library(parameters)
library(knitr)
library(kableExtra)
library(pwr)
library(ggstance)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(123)
mean_intervention <- c(0.68, 0.97, 0.40, 0.48, 0.56, 0.10, -0.10, 0.03)
mean_control      <- c(   0,    0,    0,    0,    0,    0,     0,    0)
sd_intervention   <- c(   1,    1,    1,    1,    1,    1,     1,    1)
sd_control        <- c(   1,    1,    1,    1,    1,    1,     1,    1)
n_intervention    <- c(  20,   10,  100,   37,   50,  450,    50, 1000)
n_control         <- c(  20,   10,  100,   37,   50,  450,    50, 1000)
es <- escalc(measure = "SMD",
m1i  = mean_intervention,
m2i  = mean_control,
sd1i = sd_intervention,
sd2i = sd_control,
n1i  = n_intervention,
n2i  = n_control)
es |>
as_tibble() |>
mutate_all(round_half_up, digits = 2) |>
kable() |>
kable_classic(full_width = FALSE)
es |>
summarize(mean_effect_size = round_half_up(mean(yi), digits = 2)) |>
kable() |>
kable_classic(full_width = FALSE)
lm(yi ~ 1,
data = es) |>
model_parameters()
weighted.mean(x = es$yi, w = n_intervention + n_control) |>
round_half_up(digits = 2)
lm(yi ~ 1,
weights = n_intervention + n_control,
data = es) |>
model_parameters()
lm(yi ~ 1,
weights = 1/vi,
data = es) |>
model_parameters()
rma(yi = yi,
vi = vi,
method = "FE", # fixed effect model
data = es) |>
model_parameters()
fit <-
rma(yi = yi,
vi = vi,
method = "REML", # default random effects model
data = es)
model_parameters(fit)
forest(fit, header = TRUE)
es <- escalc(measure = "SMD",
m1i  = c( 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2,  0.2),
m2i  = c(   0,   0,   0,   0,   0,   0,   0,    0),
sd1i = c(   1,   1,   1,   1,   1,   1,   1,    1),
sd2i = c(   1,   1,   1,   1,   1,   1,   1,    1),
n1i  = c(  20,  10, 100,  37,  50, 450,  50, 1000),
n2i  = c(  20,  10, 100,  37,  50, 450,  50, 1000))
rma(yi     = yi,
vi     = vi,
data   = es,
method = "REML") |>
forest(header = TRUE)
es <- escalc(measure = "SMD",
m1i  = c( 0.18, 0.43, -0.30, -0.08, 0.06, 0.10, -0.10, 0.03),
m2i  = c(    0,    0,     0,     0,    0,    0,     0,    0),
sd1i = c(    1,    1,     1,     1,    1,    1,     1,    1),
sd2i = c(    1,    1,     1,     1,    1,    1,     1,    1),
n1i  = c(   70,   50,   100,    37,   50,  350,    50,  400),
n2i  = c(   70,   50,   100,    37,   50,  350,    50,  400))
rma(yi     = yi,
vi     = vi,
data   = es,
method = "REML") |>
forest(header = TRUE)
es <- escalc(measure = "SMD",
m1i  = c( 0.68, 0.97, 0.40, 0.48, 0.56, 0.10, -0.10, 0.03),
m2i  = c(    0,    0,    0,    0,    0,    0,     0,    0),
sd1i = c(    1,    1,    1,    1,    1,    1,     1,    1),
sd2i = c(    1,    1,    1,    1,    1,    1,     1,    1),
n1i  = c(   20,   10,  100,   37,   50,  450,    50, 1000),
n2i  = c(   20,   10,  100,   37,   50,  450,    50, 1000))
res <-
rma(yi     = yi,
vi     = vi,
data   = es,
method = "REML")
forest(res, header = TRUE)
# funnel(res, level = c(90, 95, 99), refline = 0, legend = TRUE)
# summary stats
mean_intervention <- c(0.68, 0.97, 0.40, 0.48, 0.56, 0.10, -0.10, 0.03)
mean_control      <- c(   0,    0,    0,    0,    0,    0,     0,    0)
sd_intervention   <- c(   1,    1,    1,    1,    1,    1,     1,    1)
sd_control        <- c(   1,    1,    1,    1,    1,    1,     1,    1)
n_intervention    <- c(  20,   10,  100,   37,   50,  450,    50, 1000)
n_control         <- c(  20,   10,  100,   37,   50,  450,    50, 1000)
dat <-
tibble(m1i  = mean_intervention,
m2i  = mean_control,
sd1i = sd_intervention,
sd2i = sd_control,
n1i  = n_intervention,
n2i  = n_control) |>
rownames_to_column(var = "study") |>
# calculate SEs
mutate(se1i = sd1i/sqrt(n1i),
se2i = sd2i/sqrt(n2i)) |>
# replace SDs with SEs for two studies, studies 4 and 6
mutate(sd1i_error = ifelse(study %in% c("4", "6"), se1i, sd1i),
sd2i_error = ifelse(study %in% c("4", "6"), se2i, sd2i))
# calculate effect sizes properly
es_without_errors <-
escalc(measure = "SMD",
m1i  = dat$m1i,
m2i  = dat$m2i,
sd1i = dat$sd1i,
sd2i = dat$sd2i,
n1i  = dat$n1i,
n2i  = dat$n2i)
# calculate effect sizes with SE/SD errors
es_with_errors <-
escalc(measure = "SMD",
m1i  = dat$m1i,
m2i  = dat$m2i,
sd1i = dat$sd1i_error,
sd2i = dat$sd2i_error,
n1i  = dat$n1i,
n2i  = dat$n2i)
# meta-analyze the correctly calculated effect sizes
fit_correct <-
rma(yi = yi,
vi = vi,
method = "REML",
data = es_without_errors)
forest(fit_correct,
header = "Correctly calculated effect sizes")
# meta-analyze the erroneously calculated effect sizes
fit_errors <-
rma(yi = yi,
vi = vi,
method = "REML",
data = es_with_errors)
forest(fit_errors,
header = "Erroneous effect sizes: SE used as SD for two studies")
# remove all objects from environment ----
#rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(tibble)
library(forcats)
library(purrr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(janitor)
library(metafor)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(46)
# define data generating function ----
generate_data <- function(n_minimum,
n_max,
mean_control,
mean_intervention,
sd_control,
sd_intervention) {
require(tibble)
require(dplyr)
require(forcats)
n_per_condition <- runif(n = 1, min = n_minimum, max = n_max)
data_control <-
tibble(condition = "control",
score = rnorm(n = n_per_condition, mean = mean_control, sd = sd_control))
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd_intervention))
data <- bind_rows(data_control,
data_intervention) |>
# control's factor levels must be ordered so that intervention is the first level and control is the second
# this ensures that positive cohen's d values refer to intervention > control and not the other way around.
mutate(condition = fct_relevel(condition, "intervention", "control"))
return(data)
}
# define data analysis function ----
analyse_data <- function(data, probability_sig_published, probability_nonsig_published) {
require(effsize)
require(tibble)
res_n <- data |>
count()
res_t_test <- t.test(formula = score ~ condition,
data = data,
var.equal = FALSE,
alternative = "two.sided")
res_cohens_d <- effsize::cohen.d(formula = score ~ condition,  # new addition: also fit cohen's d
within = FALSE,
data = data)
res <- tibble(total_n = res_n$n,
p = res_t_test$p.value,
cohens_d_estimate = res_cohens_d$estimate,  # new addition: save cohen's d and its 95% CIs to the results tibble
cohens_d_ci_lower = res_cohens_d$conf.int["lower"],
cohens_d_ci_upper = res_cohens_d$conf.int["upper"]) |>
mutate(cohens_d_se = (cohens_d_ci_upper - cohens_d_ci_lower)/(1.96*2),
cohens_d_variance = cohens_d_se^2) |> # variance of effect size = its standard error squared
mutate(
# define result as (non)significant
significant = p < .05,
# generate a random luck probability between 0 and 1
luck = runif(n = 1, min = 0, max = 1),
# decide if the result is published or not based on whether:
# (a) the result was significant and the luck variable is higher than the probability of significant results being published, or
# (b) the result was nonsignificant and the luck variable is higher than the probability of nonsignificant results being published
published = ifelse((significant & luck >= (1 - probability_sig_published)) |
(!significant & luck >= (1 - probability_nonsig_published)), TRUE, FALSE)
)
return(res)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n_minimum = 10,
n_maximum = 100,
mean_control = 0,
mean_intervention = 0.25,
sd_control = 1,
sd_intervention = 1,
probability_sig_published = 0.70, # 0.61 from Franco et al 2014, 2016
probability_nonsig_published = 0.05, # 0.22 from Franco et al 2014, 2016
iteration = 1:25 # here iterations are studies, so the number is small relative to a normal simulation
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n_minimum,
n_maximum,
mean_control,
mean_intervention,
sd_control,
sd_intervention),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data,
probability_sig_published,
probability_nonsig_published),
analyse_data))
# summarise simulation results over the iterations ----
simulation_unnested <- simulation |>
unnest(analysis_results)
# meta analysis and forest plot
fit_all <-
rma(yi     = cohens_d_estimate,
vi     = cohens_d_variance,
data   = simulation_unnested,
method = "REML")
forest(fit_all, header = c("All studies conducted (unknowable)", "SMD [95% CI]"), xlab = "Standardized Mean Difference")
fit_published <-
rma(yi     = cohens_d_estimate,
vi     = cohens_d_variance,
data   = simulation_unnested |> filter(published == TRUE),
method = "REML")
forest(fit_published, header = c("Published studies", "SMD [95% CI]"), xlab = "Standardized Mean Difference")
# remove all objects from environment ----
#rm(list = ls())
# dependencies ----
# repeated here for the sake of completeness
library(tidyr)
library(dplyr)
library(tibble)
library(forcats)
library(purrr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(janitor)
library(metafor)
# set the seed ----
# for the pseudo random number generator to make results reproducible
set.seed(46)
# define data generating function ----
generate_data <- function(n_minimum,
n_max,
mean_control,
mean_intervention,
sd_control,
sd_intervention) {
require(tibble)
require(dplyr)
require(forcats)
n_per_condition <- runif(n = 1, min = n_minimum, max = n_max)
data_control <-
tibble(condition = "control",
score = rnorm(n = n_per_condition, mean = mean_control, sd = sd_control))
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd_intervention))
data <- bind_rows(data_control,
data_intervention) |>
# control's factor levels must be ordered so that intervention is the first level and control is the second
# this ensures that positive cohen's d values refer to intervention > control and not the other way around.
mutate(condition = fct_relevel(condition, "intervention", "control"))
return(data)
}
# define data analysis function ----
analyse_data <- function(data, probability_sig_published, probability_nonsig_published) {
require(effsize)
require(tibble)
res_n <- data |>
count()
res_t_test <- t.test(formula = score ~ condition,
data = data,
var.equal = FALSE,
alternative = "two.sided")
res_cohens_d <- effsize::cohen.d(formula = score ~ condition,  # new addition: also fit cohen's d
within = FALSE,
data = data)
res <- tibble(total_n = res_n$n,
p = res_t_test$p.value,
cohens_d_estimate = res_cohens_d$estimate,  # new addition: save cohen's d and its 95% CIs to the results tibble
cohens_d_ci_lower = res_cohens_d$conf.int["lower"],
cohens_d_ci_upper = res_cohens_d$conf.int["upper"]) |>
mutate(cohens_d_se = (cohens_d_ci_upper - cohens_d_ci_lower)/(1.96*2),
cohens_d_variance = cohens_d_se^2) |> # variance of effect size = its standard error squared
mutate(
# define result as (non)significant
significant = p < .05,
# generate a random luck probability between 0 and 1
luck = runif(n = 1, min = 0, max = 1),
# decide if the result is published or not based on whether:
# (a) the result was significant and the luck variable is higher than the probability of significant results being published, or
# (b) the result was nonsignificant and the luck variable is higher than the probability of nonsignificant results being published
published = ifelse((significant & luck >= (1 - probability_sig_published)) |
(!significant & luck >= (1 - probability_nonsig_published)), TRUE, FALSE)
)
return(res)
}
# define experiment parameters ----
experiment_parameters_grid <- expand_grid(
n_minimum = 10,
n_maximum = 100,
mean_control = 0,
mean_intervention = 0.25,
sd_control = 1,
sd_intervention = 1,
probability_sig_published = 0.70, # 0.61 from Franco et al 2014, 2016
probability_nonsig_published = 0.05, # 0.22 from Franco et al 2014, 2016
iteration = 1:25, # here iterations are studies, so the number is small relative to a normal simulation
iteration_meta = 1:10 # here iterations are studies, so the number is small relative to a normal simulation
)
# run simulation ----
simulation <-
# using the experiment parameters
experiment_parameters_grid |>
# generate data using the data generating function and the parameters relevant to data generation
mutate(generated_data = pmap(list(n_minimum,
n_maximum,
mean_control,
mean_intervention,
sd_control,
sd_intervention),
generate_data)) |>
# apply the analysis function to the generated data using the parameters relevant to analysis
mutate(analysis_results = pmap(list(generated_data,
probability_sig_published,
probability_nonsig_published),
analyse_data))
# summarise simulation results over the iterations ----
simulation_unnested <- simulation |>
unnest(analysis_results) |>
select(-generated_data) |>
group_by(n_minimum, n_maximum, mean_control, mean_intervention, sd_control, sd_intervention, probability_sig_published, probability_nonsig_published, iteration_meta) |>
nest(.key = "meta_data")
sessionInfo()
