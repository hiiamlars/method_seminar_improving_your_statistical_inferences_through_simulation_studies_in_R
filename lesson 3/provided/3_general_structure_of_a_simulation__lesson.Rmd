---
title: "General structure of a simulation study"
subtitle: "Using the example of estimating the statistical power of Student's independent *t*-test"
author: "Ian Hussey"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    highlight: haddock
    theme: flatly
    toc: yes
    toc_float: yes
---

# Overview of tutorial

This tutorial teaches you about the essential components of a simulation study and the general steps involved in actually writing one. It does this using the example of a simulation that answers a question that is relevant to many social scientists:

*The independent t-test assumes that participants are allocated equally to two groups. How much does an unbalanced design lower the statistical power of the test?*

We will somewhat gloss over some important details, e.g., the specifics of how data is generated using pseudo random number generators, a more fine-grained treatment of how we write functions, and diagnostics of whether your simulation is performing well. We will return to these in future lessons.

# License

[CC BY 4.0](https://creativecommons.org/licenses/by/4.0/deed.en)

```{r, include=FALSE}

# set default chunk options
knitr::opts_chunk$set(message = FALSE,
                      warning = FALSE)

# disable scientific notation
options(scipen = 999) 

```

# Essential components & general steps 

The essential *components* of a simulation are:

1. Generate pseudo-random data set with known properties
2. Analyse data with a statistical method
3. Repeat 1 & 2 many times (‘iterations’)
4. Collect and aggregate results across iterations
5. Make it an experiment: Systematically vary parameters in Step 1 (between factor) and/or compare different ways to do Step 2 (within factor)

However, the way you *build* a simulation is much more iterative than this final product. Each component must be both built and inspected by itself, and then checked to make sure that the components work together in the correct manner, like a fine Swiss watch. 

The general steps for actually building one involve:

1. Generate a *single* pseudo-random data set with known properties, using hard-coded variables
2. Analyse this *single* data set with a statistical method, using hard-coded variables
3. Convert the data generation code to a function, making it as abstract as necessary  [Component 1]
4. Convert the data analysis code to a function, making it as abstract as necessary  [Component 2]
5. Ensure that experiment parameters, data generation function, and data analysis code play together nicely (i.e., can pass values between one another in a workflow, and save values appropriately [Component 4]). Do this using a small number of parameters and just one or two iterations.
6. Increase the number of iterations and parameters and actually run the simulation as a whole [Component 4 and 5]
7. Check the assumptions of the simulation have been adequately met
8. Interpret the results of the simulation

This tutorial focuses on the general practical steps, but always keep the essential components in mind as the guiding principles of why we're doing something.

# Dependencies

```{r}

library(tidyr)
library(dplyr)
library(forcats)
library(readr)
library(purrr) 
library(ggplot2)
library(effsize)

```

# Generate data and apply and analysis *once* using hard coded arguments

## Generate some data for an independent t-test

- condition: factor with two levels (control, intervention)
- score: numeric of normally distributed data (within each condition), with different means, and SD = 1.
- given that cohen's d = (m2 - m1)/SD_pooled, simply setting SDs to 1 and mean_control to 0 lets us control the cohen's d = mean_intervention
- use the R function `rnorm`

To sample data from a normally distributed population, we use the pseudo-random number generator for normal data built into R: `rnorm()`. Note that many packages exist to help you generate different types of data more easily, including {MASS}, {faux}, {simstudy}, and {lavaan}. These can be very helpful, but here we'll do it manually for the moment.

### Try it yourself first

```{r}

# set the seed value for pseudo random number generators to make results reproducible  
set.seed(42)



```

### Solution

```{r}

# set the seed value for pseudo random number generators to make results reproducible  
set.seed(42)

data_control <- 
  tibble(condition = "control",
         score = rnorm(n = 50, mean = 0, sd = 1))

data_intervention <- 
  tibble(condition = "intervention",
         score = rnorm(n = 50, mean = 0.50, sd = 1))

data_combined <- bind_rows(data_control,
                           data_intervention)

View(data_combined)

```

## Fit a Student's independent *t*-test

To the data we just generated.

Use `t.test`

### Try it yourself

```{r}



```

### Solution

```{r}

t.test(formula = score ~ condition, 
       data = data_combined,
       var.equal = TRUE,
       alternative = "two.sided")

```

# Create a data generating function

## Make the existing code more abstract

Move the values used as parameters in the `rnorm()` call to variables.

### Try it yourself

```{r}

data_control <- 
  tibble(condition = "control",
         score = rnorm(n = n_control, mean = mean_control, sd = sd_control))

data_intervention <- 
  tibble(condition = "intervention",
         score = rnorm(n = n_intervention, mean = mean_intervention, sd = sd_intervention))

data_combined <- bind_rows(data_control,
                           data_intervention)

```

### Solution

```{r}

# parameters for simulated data
n_control <- 50
n_intervention <- n_control
mean_control <- 0
mean_intervention <- 0.5
sd_control <- 1
sd_intervention <- sd_control

# generate data using these parameters
data_control <- 
  tibble(condition = "control",
         score = rnorm(n = n_control, mean = mean_control, sd = sd_control))

data_intervention <- 
  tibble(condition = "intervention",
         score = rnorm(n = n_intervention, mean = mean_intervention, sd = sd_intervention))

data_combined <- bind_rows(data_control,
                           data_intervention)

# view the generated data
View(data_combined)

```

## Convert this to a function

Abstracting code into functions is a learned skill. For the moment, see if you can follow the logic of the function and where it came from in the hard coded original version. 

### Try it yourself

```{r}

# parameters for simulated data
n_control <- 50
n_intervention <- n_control
mean_control <- 0
mean_intervention <- 0.5
sd_control <- 1
sd_intervention <- sd_control

# generate data using these parameters
data_control <- 
  tibble(condition = "control",
         score = rnorm(n = n_control, mean = mean_control, sd = sd_control))

data_intervention <- 
  tibble(condition = "intervention",
         score = rnorm(n = n_intervention, mean = mean_intervention, sd = sd_intervention))

data_combined <- bind_rows(data_control,
                           data_intervention)

# view the generated data
View(data_combined)

```

### Solution

```{r}

# define function
generate_data <- function(n_control, # the parameters are now function arguments
                          n_intervention,
                          mean_control,
                          mean_intervention,
                          sd_control,
                          sd_intervention) {
  
  data_control <- 
    tibble(condition = "control",
           score = rnorm(n = n_control, mean = mean_control, sd = sd_control))
  
  data_intervention <- 
    tibble(condition = "intervention",
           score = rnorm(n = n_intervention, mean = mean_intervention, sd = sd_intervention))
  
  data_combined <- bind_rows(data_control,
                             data_intervention)
  
  return(data_combined)
}

# call the function with example arguments
generated_data <- generate_data(n_control = 50,
                                n_intervention = 50,
                                mean_control = 0,
                                mean_intervention = 0.5,
                                sd_control = 1,
                                sd_intervention = 1)

# view the generated data
View(generated_data)

```

- Now change the above function to use default values for SDs, with both SDs = 1. Check that the function works even when you don't specify SDs when calling the function.

## Check the generated data still works with the *t*-test

In general, you should inspect the data thoroughly, check the data types, plot it, conduct other sanity checks, etc. For the moment, we apply just the most basic test: check that the analysis can be fit to data generated by the data generation function. For the moment, the specific results don't matter as much as whether it can accept the data. That is, your data generation will have to be aligned with your data analysis code (e.g., both make use of the variables score [continuous] and condition [factor with two levels]).

```{r}

t.test(formula = score ~ condition, 
       data = generated_data, # using the data generated in the previous chunk
       var.equal = TRUE,
       alternative = "two.sided")

```

# Create a data analysis function

## Make the existing code more abstract

Now do the same abstraction for the analysis.

Rather than just printing all the results of the t test to the console, extract the p value specifically as a column in a tibble. In general, you usually want to extract the results of analyses in `tidy data` format. Note that the {parameters} and {broom} packages can be very helpful for doing this for you for many common types of analysis, but here we're do it manually.

### Try it yourself

```{r}

t.test(formula = score ~ condition, 
       data = generated_data, 
       var.equal = TRUE,
       alternative = "two.sided")

```

### Solution

```{r}

res_t_test <- t.test(formula = score ~ condition, 
                     data = generated_data,
                     var.equal = TRUE,
                     alternative = "two.sided")

res <- tibble(p = res_t_test$p.value)

res

```

## Convert this to a function

### Try it yourself

```{r}

res_t_test <- t.test(formula = score ~ condition, 
                     data = generated_data,
                     var.equal = TRUE,
                     alternative = "two.sided")

res <- tibble(p = res_t_test$p.value)

res

```

### Solution

```{r}

analyze_data <- function(data) {
  
  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = TRUE,
                       alternative = "two.sided")
  
  res <- tibble(p = res_t_test$p.value)
  
  return(res)
}

```

# Compare original hard-coded version with functionalised version

## Original manual code, copied from above

```{r}

set.seed(42)

data_control <- 
  tibble(condition = "control",
         score = rnorm(n = 50, mean = 0, sd = 1))

data_intervention <- 
  tibble(condition = "intervention",
         score = rnorm(n = 50, mean = 0.5, sd = 1))

data_combined <- bind_rows(data_control,
                           data_intervention)

t.test(formula = score ~ condition, 
       data = data_combined,
       var.equal = TRUE,
       alternative = "two.sided")

```

## New code using functions, copied from above

```{r}

set.seed(42)

generated_data <- generate_data(n_control = 50,
                                n_intervention = 50,
                                mean_control = 0,
                                mean_intervention = 0.5,
                                sd_control = 1,
                                sd_intervention = 1)

results <- analyze_data(generated_data)

results

```

# Do it lots of times and summarize across them

For the moment, we'll use a for-loop to accomplish this. You don't need to practice this as you generally won't use for loops in this class, but it's easier to illustrate what's happening with this.

```{r}

set.seed(42)

# define the number of iterations
iterations <- 100

# declare a vector to store each iteration's results in
p_values <- numeric(iterations)

# use for loop to repeat its content many times
# for the 'i'-th element of the series 1 to `iterations` (i.e., 1, 2, 3, ... iterations), run the following code:
for(i in 1:iterations){ 
  # generate data
  generated_data <- generate_data(n_control = 50,
                                  n_intervention = 50,
                                  mean_control = 0,
                                  mean_intervention = 0.5,
                                  sd_control = 1,
                                  sd_intervention = 1)
  
  # analyse data
  results <- analyze_data(generated_data)
  
  # store result of this iteration
  # the i-th element of the iterations vector will be replaced with the p value of the current iteration's t-test
  p_values[i] <- results$p
}

# summarize individual analysis results across iterations to find stimulation results
mean(p_values < .05)

```

Congratulations, you've just run your first simulation. Let's remind ourselves what it does.

- Data generating process (i.e., population effect): true effect Cohen's d = 0.50 (i.e., difference in means = 0.50, both SDs = 1), with 50 participants per condition.
- Data analysis: independent t-test p value.
- Iterations: 100
- Summary across iterations: For 50 participants per condition, when the true population effect exists (is non zero, i.e., Cohen's d = .50), an independent t-test produces statistically significant p values in `r round(mean(p_values < .05)*100, 1)`% of cases. This is the definition of statistical power: the proportion of cases where effects that do exist are detected (i.e., true-positive results). 

# What if I want my simulation to do more complex things?

The above code isn't enough because we want our simulation to be an experiment with multiple between-conditions. How might we accomplish this?

We could extend the method above, but it gets tricky very quickly.

For example, if I wanted to see how changing the number of participants in (a) the control condition and (b) the intervention condition so that either can be anywhere between 50 and 250 (in steps of 50), including having different number between them (e.g., control = 200, intervention = 100), then I'll have to either:

- Repeat my code a lot. This is always a bad idea. Repeating simple tasks we're bad at doing ourselves is the reason we invented computers.
- Abstract the code further in some way, such as using more for-loops.

Before you look at this code, know that it much harder to understand and much harder to write too. I'm showing you this method so that you know it exists and is the most basic way of doing it - not because we are going to do it in any of the rest of this course.

```{r}

set.seed(42)

# define the number of iterations
iterations <- 100
n_control_conditions <- seq(from = 50, to = 250, by = 50)
n_intervention_conditions <- seq(from = 50, to = 250, by = 50)

# initialize results list
simulation_results <- list()

# counter for appending results
result_counter <- 1

# use nested for loops to iterate over conditions
for(k in n_intervention_conditions){ # for each of the 'k'-th members of the n_intervention_conditions vector ... 
  for(j in n_control_conditions){ # ... and for each of the 'j'-th members of the n_control_conditions vector ...
    for(i in 1:iterations){ # ... and for each value of 'i' in the sequence 1 to iterations, run the following code with those values of i, j, and k:
      
      # generate data
      generated_data <- generate_data(n_control = j,  # current value of j
                                      n_intervention = k,  # current value of k
                                      mean_control = 0,
                                      mean_intervention = 0.5,
                                      sd_control = 1,
                                      sd_intervention = 1)
      
      # analyse data
      results <- analyze_data(generated_data)
      
      # save results for this iteration as the 'result_counter'-th member of the simulation_results list
      simulation_results[[result_counter]] <- list(
        n_control = j, # current value of j
        n_intervention = k, # current value of k
        p_value = results$p  # current value the t test's p value
      )
      
      # increment the iteration counter
      result_counter <- result_counter + 1
    }
  }
}

# convert the list-of-lists into a data frame, as its easier to wrangle and plot
simulation_results_df <- bind_rows(simulation_results)

# summarize individual analysis results across iterations to find stimulation results
# ie plot as a bar plot
simulation_results_df |>
  mutate(n_control = as.factor(n_control),
         n_intervention = as.factor(n_intervention)) |>
  group_by(n_control, n_intervention) |>
  summarize(power = mean(p_value < .05), .groups = "drop") |>
  ggplot(aes(n_control, power, fill = n_intervention)) +
  geom_col(position = position_dodge(width = 0.4), width = 0.4) +
  scale_fill_viridis_d(option = "mako", begin = 0.3, end = 0.8, 
                       guide = guide_legend(reverse = TRUE)) +
  theme_linedraw() +
  ggtitle("All conditions") +
  ylab("Estimated statistical power")

```

# A better way using {dplyr} and {purrr} 

**Note: stop here and talk about tidy nested data before proceeding**

There are many other ways to implement simulations, using solutions written in base R, purrr, and other packages such as SimDesign and simhelpers. 

My goal here is to teach you an approach that is both flexible and intuitive for those who understand dplyr well already. It prioritizes retaining all objects created within the simulation so that they are visible and checkable, whereas other solutions make intermediate steps invisible and abstract which is often difficult for new learners. 

```{r}

# define experiment parameters
# and use expand_grid (the {tidyr} version of expand.grid) to create a data frame of all their permutations
# note that each variable can have just one value or multiple values
experiment_parameters_grid <- expand_grid(
  n_control = seq(from = 50, to = 250, by = 50),
  n_intervention = seq(from = 50, to = 250, by = 50),
  mean_control = 0,
  mean_intervention = 0.5,
  sd_control = 1,
  sd_intervention = 1,
  iteration = 1:100 # note this is a series not an integer, i.e., "1:100" not "100", as "100" would mean just one iteration called "100".
)


simulation <- 
  # "using the experiment parameters..."
  experiment_parameters_grid |>
  
  # "...generate data using the data generating function and the parameters relevant to data generation ..."
  # NB pmap() passes a list of parameters to the function listed as its second argument (generate_data).
  # when used inside a mutate call like this, its saying "for each row, create a new column (generated_data)
  # by calling a function (generate_data) and use the following list of columns as its arguments.
  # ensure the list orders the arguments in the same order as the function takes them, as they are passed to the function in this order!
  mutate(generated_data = pmap(list(n_control, 
                                    n_intervention,
                                    mean_control,
                                    mean_intervention,
                                    sd_control,
                                    sd_intervention),
                               generate_data)) |>
  
  # "... then apply the analysis function to the generated data using the parameters relevant to analysis ..."
  # again ensure they are listed in the correct order, as they are passed to the function in this order!
  mutate(analysis_results = pmap(list(generated_data),
                                 analyze_data))


# "... then summarise results across iterations"
simulation_summary <- simulation |>
  # convert this column in the df that is a nested data frame into columns in the df
  unnest(analysis_results) |> 
  # convert these variables into factors for plotting
  mutate(n_control = as.factor(n_control), 
         n_intervention = as.factor(n_intervention)) |>
  # for each level of n_control and n_intervention, calculate power (proportion of iterations where signficiant results were found)
  summarize(power = mean(p < .05), 
            .by = c(n_control, n_intervention))

# plot results
ggplot(simulation_summary, aes(n_control, power, fill = n_intervention)) +
  geom_col(position = position_dodge(width = 0.4), width = 0.4) +
  scale_fill_viridis_d(option = "mako", begin = 0.3, end = 0.8, 
                       guide = guide_legend(reverse = TRUE)) +
  theme_linedraw() +
  ggtitle("All conditions") +
  ylab("Estimated statistical power")

```

- Inspect the parameters grid to see how it contains a row for each iteration to be run, containing all the parameters for that iteration.
- View the `simulation` data frame: notice that it saves the data and results from each iteration as a "nested data frame" column. You can click on each cell to open it and see the data frame contained.
- It's really important to understand the pmap() call here. It allows us to effectively run the following code on each row, while avoiding using `rowwise()` because that can be much slower and cause issues later. However, it can help to see it implemented using rowwise() (without pmap()) to understand it. If it helps you to understand it, you can write your own simulations this way for the moment but note that they'll be slower to run.

```{r}

simulation_alt <- 
  # "using the experiment parameters..."
  experiment_parameters_grid |>
  
  # "...generate data using the data generating function and the parameters relevant to data generation ..."
  rowwise() |> # without pmap(), you need a rowwise() call to use only the values from this row as input in the next line.
  # note how the output of generate_data() has to be converted to a list() to be saved in a single cell.
  mutate(generated_data = list(generate_data(n_control = n_control, 
                                             n_intervention = n_intervention,
                                             mean_control = mean_control,
                                             mean_intervention = mean_intervention,
                                             sd_control = sd_control,
                                             sd_intervention = sd_intervention))) |>
  
  # "... then apply the analysis function to the generated data using the parameters relevant to analysis ..."
  mutate(analysis_results = list(analyze_data(data = generated_data))) |>
  ungroup() # once the operations that need to be completed rowwise() are complete you should ungroup() the data again so it doesn't have unintended consequences in later code.

```

## The flexibility of this approach

This approach where we (a) define a grid of all the parameters and iterations we want to run, (b) map our data generation and analysis functions onto each row, saving nested data frames each time, is extremely scalable. By this, I mean that we can examine any other values of these parameters that we like, or indeed change some parameters from being static single parameters to having multiple ones (i.e., experimentally manipulate them), without having to write additional for-loops to handle them. 

For example, let's simulate more than one true effect size and see how power changes with true effect size too.

```{r fig.height=5, fig.width=10}

# define experiment parameters
experiment_parameters_grid <- expand_grid(
  n_control = seq(from = 50, to = 250, by = 50),
  n_intervention = seq(from = 50, to = 250, by = 50),
  mean_control = 0,
  mean_intervention = c(0.2, 0.5, 0.8), # I've added additional values here for small, medium, & large Cohen's d  - this is the only change to the code
  sd_control = 1,
  sd_intervention = 1,
  iteration = 1:100 
)

simulation <- 
  # using the experiment parameters
  experiment_parameters_grid |>
  
  # generate data using the data generating function and the parameters relevant to data generation
  mutate(generated_data = pmap(list(n_control,
                                    n_intervention,
                                    mean_control,
                                    mean_intervention,
                                    sd_control,
                                    sd_intervention),
                               generate_data)) |>
  
  # apply the analysis function to the generated data using the parameters relevant to analysis
  mutate(analysis_results = pmap(list(generated_data),
                                 analyze_data))


# summarise results across iterations
simulation_summary <- simulation |>
  unnest(analysis_results) |>
  mutate(n_control = as.factor(n_control),
         n_intervention = as.factor(n_intervention),
         true_effect = paste("Cohen's d =", mean_intervention)) |>
  group_by(n_control,
           n_intervention,
           true_effect) |>
  summarize(power = mean(p < .05), .groups = "drop")

# plot summary
ggplot(simulation_summary, aes(n_control, power, fill = n_intervention)) +
  geom_col(position = position_dodge(width = 0.4), width = 0.4) +
  scale_fill_viridis_d(option = "mako", begin = 0.3, end = 0.8, 
                       guide = guide_legend(reverse = TRUE)) +
  theme_linedraw() +
  ggtitle("All conditions") +
  ylab("Estimated statistical power") +
  facet_wrap(~ true_effect)

```

## Extending this simulation

We saw above that this approach allows us to easily simulate additional conditions simply by including them in our expand_grid parameters. If we want to simulate additional conditions or collect additional data from, we can also easily modify our data generation or data analysis functions to do this, (often) without having to change other components of the simulation, or without having to change them much (e.g., by adding additional parameters to the expand grid).

For example, if we want our analysis to save the p values but also the Cohen's d effect sizes, we can modify the function to do this. 

```{r fig.height=5, fig.width=10}

# redefine the data generation function
generate_data <- function(n_control, # the parameters are now function arguments
                          n_intervention,
                          mean_control,
                          mean_intervention,
                          sd_control,
                          sd_intervention) {
  
  data <- 
    bind_rows(
      tibble(condition = "control",
             score = rnorm(n = n_control, mean = mean_control, sd = sd_control)),
      tibble(condition = "intervention",
             score = rnorm(n = n_intervention, mean = mean_intervention, sd = sd_intervention))
    ) |>
    # new addition: control's factor levels must be ordered so that intervention is the first level and control is the second
    # this ensures that positive cohen's d values refer to intervention > control and not the other way around.
    mutate(condition = fct_relevel(condition, "intervention", "control"))
  
  return(data)
}

# redefine the analysis function
analyze_data <- function(data) {
  # dependencies
  require(effsize)
  
  res_t_test <- t.test(formula = score ~ condition, 
                       data = data,
                       var.equal = TRUE,
                       alternative = "two.sided")
  
  res_cohens_d <- effsize::cohen.d(formula = score ~ condition,  # new addition: also fit cohen's d
                                   within = FALSE,
                                   data = data)
  
  res <- tibble(p = res_t_test$p.value, 
                cohens_d = res_cohens_d$estimate,  # new addition: save cohen's d and its 95% CIs to the results tibble
                cohens_d_ci_lower = res_cohens_d$conf.int["lower"],
                cohens_d_ci_upper = res_cohens_d$conf.int["upper"])
  
  return(res)
}


# the code for running the simulation remains unchanged:

# define experiment parameters
experiment_parameters_grid <- expand_grid(
  n_control = 50,
  n_intervention = 50,
  mean_control = 0,
  mean_intervention = c(0.2, 0.5, 0.8), # small, medium, large Cohen's d 
  sd_control = 1,
  sd_intervention = 1,
  iteration = 1:100 
)

# run simulation
simulation <- 
  # using the experiment parameters
  experiment_parameters_grid |>
  
  # generate data using the data generating function and the parameters relevant to data generation
  mutate(generated_data = pmap(list(n_control,
                                    n_intervention,
                                    mean_control,
                                    mean_intervention,
                                    sd_control,
                                    sd_intervention),
                               generate_data)) |>
  
  # apply the analysis function to the generated data using the parameters relevant to analysis
  mutate(analysis_results = pmap(list(generated_data),
                                 analyze_data))


# summarise across iterations 
simulation_summary <- simulation |>
  unnest(analysis_results) |>
  mutate(n_control = as.factor(n_control),
         n_intervention = as.factor(n_intervention),
         true_effect = paste("Cohen's d =", mean_intervention)) |>
  group_by(n_control,
           n_intervention,
           true_effect) |>
  summarize(power = mean(p < .05), # power: proportion of iterations where significant results were found when true effect is != zero.
            # new: mean half-CI-width. ie with this sample size, how wide are its 95% CIs, ± the point estimate?
            mean_cohens_d_precision = mean((cohens_d_ci_upper - cohens_d_ci_lower)/2), 
            .groups = "drop")

# plot power 
ggplot(simulation_summary, aes(n_control, power)) +
  geom_col(position = position_dodge(width = 0.4), width = 0.4) +
  scale_fill_viridis_d(option = "mako", begin = 0.3, end = 0.8, 
                       guide = guide_legend(reverse = TRUE)) +
  theme_linedraw() +
  ylab("Estimated statistical power") +
  xlab("N per condition") +
  facet_wrap(~ true_effect)

# new plot: precision of cohen's d
ggplot(simulation_summary, aes(n_control, mean_cohens_d_precision)) +
  geom_col(position = position_dodge(width = 0.4), width = 0.4) +
  scale_fill_viridis_d(option = "mako", begin = 0.3, end = 0.8, 
                       guide = guide_legend(reverse = TRUE)) +
  theme_linedraw() +
  ylab("Precision of Cohen's d\n(mean half-95% CI width)") +
  xlab("N per condition") +
  facet_wrap(~ true_effect)

```

# Session info

```{r}

sessionInfo()

```


