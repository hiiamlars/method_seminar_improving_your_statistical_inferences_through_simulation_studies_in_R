# plot results
ggplot(simulation_summary, aes(population_effect_size, proportion_of_significant_p_values)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 10),
limits = c(0,1),
name = "Proportion of significant p-values") +
scale_x_discrete(name = "Population effect size")
# plot results
ggplot(simulation_summary, aes(n_per_condition, proportion_of_significant_p_values)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 10),
limits = c(0,1),
name = "Proportion of significant p-values") +
scale_x_discrete(name = "Population size")
# summarize across iterations
simulation_summary <- simulation |>
# unnest results
unnest(results) |>
# for each level of n_per_condition...
group_by(n_per_condition) |>
# ... calculate proportion of iterations where significant results were found
mutate(significant = p < .05) |>
summarize(proportion_of_significant_p_values = mean(significant)) |>
# make n_per_condition a factor for plotting
mutate(n_per_condition = as.factor(n_per_condition))
# plot results
ggplot(simulation_summary, aes(n_per_condition, proportion_of_significant_p_values)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 10),
limits = c(0,1),
name = "Proportion of significant p-values") +
scale_x_discrete(name = "Population size")
?cohen.d()
# remove all objects from environment to ensure you're starting from a blank page
rm(list = ls())
# set seed
set.seed(42)
# functions for simulation
generate_data <- function(n_per_condition,
mean_control,
mean_intervention,
sd) {
data_control <-
tibble(condition = "control",
score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
data_combined <- bind_rows(data_control,
data_intervention)
return(data_combined)
}
# simulation parameters
experiment_parameters <- expand_grid(
n_per_condition = 50,
mean_control = 0,
mean_intervention = c(0, 0.5),
sd = 1,
iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error.
) |>
# because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
# because d = [mean_intervention - mean_control]/SD_pooled
# for clarity, let's just make a variable called population_effect_size
mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data))# |>
View(experiment_parameters)
View(simulation[[7]][[1]])
effsize::cohen.d(formula = score ~ condition,
data = pmap(list(simulation$generated_data)),
pooled = TRUE) |>
effsize::cohen.d()
# remove all objects from environment to ensure you're starting from a blank page
rm(list = ls())
# set seed
set.seed(42)
# functions for simulation
generate_data <- function(n_per_condition,
mean_control,
mean_intervention,
sd) {
data_control <-
tibble(condition = "control",
score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
data_combined <- bind_rows(data_control,
data_intervention)
return(data_combined)
}
res <- generate_data(50, 0, 0.5, 1)
View(res)
res_cohen_d <- effsize::cohen.d(res$score ~ res$condition)
View(res_cohen_d)
res_cohen_d <- effsize::cohen.d(res$score ~ res$condition)$estimate
res_cohen_d <- effsize::cohen.d(res$score ~ res$condition,
pooled = TRUE)$estimate
# remove all objects from environment to ensure you're starting from a blank page
rm(list = ls())
# set seed
set.seed(42)
# functions for simulation
generate_data <- function(n_per_condition,
mean_control,
mean_intervention,
sd) {
data_control <-
tibble(condition = "control",
score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
data_combined <- bind_rows(data_control,
data_intervention)
return(data_combined)
}
analyze <- function(data) {
res_cohens_d <- effsize::cohen.d(res$score ~ res$condition,
pooled = TRUE)
res <- tibble(p = res_cohens_d$estimate)
return(res)
}
# simulation parameters
experiment_parameters <- expand_grid(
n_per_condition = 50,
mean_control = 0,
mean_intervention = c(0, 0.5),
sd = 1,
iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error.
) |>
# because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
# because d = [mean_intervention - mean_control]/SD_pooled
# for clarity, let's just make a variable called population_effect_size
mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))
View(experiment_parameters)
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data)) |>
mutate(results = pmap(list(generated_data),
analyze))
analyze <- function(data) {
res_cohens_d <- effsize::cohen.d(score ~ condition,
pooled = TRUE)
res <- tibble(p = res_cohens_d$estimate)
return(res)
}
# simulation parameters
experiment_parameters <- expand_grid(
n_per_condition = 50,
mean_control = 0,
mean_intervention = c(0, 0.5),
sd = 1,
iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error.
) |>
# because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
# because d = [mean_intervention - mean_control]/SD_pooled
# for clarity, let's just make a variable called population_effect_size
mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data)) |>
mutate(results = pmap(list(generated_data),
analyze))
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data))# |>
View(simulation)
View(simulation[[7]][[1]])
res_cohens_d <- simulation |>
pmap(list(generated_data)) |>
effsize::cohen.d(score ~ condition,
pooled = TRUE)
res_cohens_d <- simulation$generated_data |>
pmap(list()) |>
effsize::cohen.d(score ~ condition,
pooled = TRUE)
data_control <-
tibble(condition = "control",
score = rnorm(n = 50, mean = 0, sd = 1))
data_combined <- bind_rows(data_control,
data_intervention)
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = 50, mean = 0, sd = 1))
data_combined <- bind_rows(data_control,
data_intervention)
effsize::cohen.d(data_combined$score ~ data_combined$condition,
pooled = TRUE)
res_cohens_d <- effsize::cohen.d(data_combined$score ~ data_combined$condition,
pooled = TRUE)
res <- tibble(p = res_cohens_d$estimate)
View(res)
analyze <- function(data) {
res_cohens_d <- effsize::cohen.d(score ~ condition,
pooled = TRUE)
res <- tibble(p = res_cohens_d$estimate)
return(res)
}
# simulation parameters
experiment_parameters <- expand_grid(
n_per_condition = 50,
mean_control = 0,
mean_intervention = c(0, 0.5),
sd = 1,
iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error.
) |>
# because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
# because d = [mean_intervention - mean_control]/SD_pooled
# for clarity, let's just make a variable called population_effect_size
mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data))# |>
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data))# |>
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data))# |>
mutate(results = pmap(list(generated_data),
analyze)
View(simulation)
View(simulation)
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data)) |>
mutate(results = pmap(list(generated_data),
analyze))
View(data_combined)
res_cohens_d <- effsize::cohen.d(formula = score ~ data_combined,
data = data_combined,
pooled = TRUE)
View(simulation[[7]][[1]])
res_cohens_d <- effsize::cohen.d(formula = score ~ condition,
data = data_combined,
pooled = TRUE)
res <- tibble(p = res_cohens_d$estimate)
View(res)
# remove all objects from environment to ensure you're starting from a blank page
rm(list = ls())
# set seed
set.seed(42)
# functions for simulation
generate_data <- function(n_per_condition,
mean_control,
mean_intervention,
sd) {
data_control <-
tibble(condition = "control",
score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
data_combined <- bind_rows(data_control,
data_intervention)
return(data_combined)
}
analyze <- function(data) {
res_cohens_d <- effsize::cohen.d(formula = score ~ condition,
data = data_combined,
pooled = TRUE)
res <- tibble(p = res_cohens_d$estimate)
return(res)
}
analyze <- function(data) {
res_cohens_d <- effsize::cohen.d(formula = score ~ condition,
data = data,
pooled = TRUE)
res <- tibble(p = res_cohens_d$estimate)
return(res)
}
# simulation parameters
experiment_parameters <- expand_grid(
n_per_condition = 50,
mean_control = 0,
mean_intervention = c(0, 0.5),
sd = 1,
iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error.
) |>
# because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
# because d = [mean_intervention - mean_control]/SD_pooled
# for clarity, let's just make a variable called population_effect_size
mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data)) |>
mutate(results = pmap(list(generated_data),
analyze))
View(simulation)
View(simulation[[8]][[1]])
analyze <- function(data) {
res_cohens_d <- effsize::cohen.d(formula = score ~ condition,
data = data,
pooled = TRUE)
res <- tibble(cohens_d = res_cohens_d$estimate)
return(res)
}
# simulation parameters
experiment_parameters <- expand_grid(
n_per_condition = 50,
mean_control = 0,
mean_intervention = c(0, 0.5),
sd = 1,
iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error.
) |>
# because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
# because d = [mean_intervention - mean_control]/SD_pooled
# for clarity, let's just make a variable called population_effect_size
mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data)) |>
mutate(results = pmap(list(generated_data),
analyze))
View(simulation)
View(simulation[[8]][[1]])
View(simulation)
View(simulation)
# summarize across iterations
simulation_summary <- simulation |>
# unnest results
unnest(results) #|>
View(simulation_summary)
# summarize across iterations
simulation_summary <- simulation |>
# unnest results
unnest(results) |>
# for each level of mean_intervention...
group_by(population_effect_size) |>
summarize(average_cohens_d = mean(results))
# summarize across iterations
simulation_summary <- simulation |>
# unnest results
unnest(results) |>
# for each level of mean_intervention...
group_by(population_effect_size) |>
summarize(average_cohens_d = mean(cohens_d))
# table of results
simulation_summary |>
kable() |>
kable_classic(full_width = FALSE)
# plot results
ggplot(simulation_summary, aes(population_effect_size, proportion_of_significant_p_values)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 10),
limits = c(0,1),
name = "Proportion of significant p-values") +
scale_x_discrete(name = "Population effect size")
# plot results
ggplot(simulation_summary, aes(population_effect_size, average_cohens_d)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 10),
limits = c(0,1),
name = "Proportion of significant p-values") +
scale_x_discrete(name = "Population effect size")
# plot results
ggplot(simulation_summary, aes(population_effect_size, average_cohens_d)) +
geom_col() +
theme_linedraw() #+
# summarize across iterations
simulation_summary <- simulation |>
# unnest results
unnest(results) #|>
# plot results
ggplot(simulation_summary, aes(population_effect_size, average_cohens_d)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 20),
limits = c(-1,1),
name = "Proportion of significant p-values") +
scale_x_discrete(name = "Population effect size")
# summarize across iterations
simulation_summary <- simulation |>
# unnest results
unnest(results) |>
# for each level of mean_intervention...
group_by(population_effect_size) |>
#... calculate the average Cohen's d
summarize(average_cohens_d = mean(cohens_d))
# table of results
simulation_summary |>
kable() |>
kable_classic(full_width = FALSE)
# plot results
ggplot(simulation_summary, aes(population_effect_size, average_cohens_d)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 20),
limits = c(-1,1),
name = "Proportion of significant p-values") +
scale_x_discrete(name = "Population effect size")
# plot results
ggplot(simulation_summary, aes(population_effect_size, average_cohens_d)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 20),
limits = c(-1,1),
name = "Mean estimate of cohens d") +
scale_x_discrete(name = "Population effect size")
# remove all objects from environment to ensure you're starting from a blank page
rm(list = ls())
# set seed
set.seed(42)
# functions for simulation
generate_data <- function(n_per_condition,
mean_control,
mean_intervention,
sd) {
data_control <-
tibble(condition = "control",
score = rnorm(n = n_per_condition, mean = mean_control, sd = sd))
data_intervention <-
tibble(condition = "intervention",
score = rnorm(n = n_per_condition, mean = mean_intervention, sd = sd))
data_combined <- bind_rows(data_control,
data_intervention)
return(data_combined)
}
analyze <- function(data) {
res_cohens_d <- effsize::cohen.d(formula = score ~ condition,
data = data,
pooled = TRUE)
res <- tibble(cohens_d = res_cohens_d$estimate)
return(res)
}
# simulation parameters
experiment_parameters <- expand_grid(
n_per_condition = 50,
mean_control = 0,
mean_intervention = c(0, 0.5),
sd = 1,
iteration = 1:10000 # note that number of iterations has been increased to provide more stable estimates / lower monte-carlo error.
) |>
# because mean_control is 0 and both SDs are 1, mean_intervention is really a proxy for Cohen's d
# because d = [mean_intervention - mean_control]/SD_pooled
# for clarity, let's just make a variable called population_effect_size
mutate(population_effect_size = paste0("Cohen's d = ", mean_intervention))
# run simulation
simulation <- experiment_parameters |>
mutate(generated_data = pmap(list(n_per_condition,
mean_control,
mean_intervention,
sd),
generate_data)) |>
mutate(results = pmap(list(generated_data),
analyze))
# summarize across iterations
simulation_summary <- simulation |>
# unnest results
unnest(results) |>
# for each level of mean_intervention...
group_by(population_effect_size) |>
#... calculate the average Cohen's d
summarize(average_cohens_d = mean(cohens_d))
# table of results
simulation_summary |>
kable() |>
kable_classic(full_width = FALSE)
# plot results
ggplot(simulation_summary, aes(population_effect_size, average_cohens_d)) +
geom_col() +
theme_linedraw() +
scale_y_continuous(breaks = breaks_pretty(n = 20),
limits = c(-1,1),
name = "Mean estimate of cohens d") +
scale_x_discrete(name = "Population effect size")
